{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Introduction to Multivariate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental statistics are useful tools in applied machine learning for a better understanding\n",
    "your data. They are also the tools that provide the foundation for more advanced linear algebra\n",
    "operations and machine learning methods, such as the covariance matrix and principal component\n",
    "analysis respectively. As such, it is important to have a strong grip on fundamental statistics\n",
    "in the context of linear algebra notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Expected Value and Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability, the average value of some random variable $X$ is called the expected value or the expectation. The expected value uses the notation $E$ with square brackets around the name of the variable; for example:\n",
    "\n",
    "$$\n",
    "E[X]\n",
    "$$\n",
    "\n",
    "It is calculated as the probability weighted sum of values that can be drawn.\n",
    "\n",
    "$$\n",
    "E[X] = \\sum x_1 \\times p_1, x_2 \\times p_2, x_3 \\times p_3, \\cdots , x_n \\times p_n \n",
    "$$\n",
    "\n",
    "In simple cases, such as the flipping of a coin or rolling a dice, the probability of each event is just as likely. Therefore, the expected value can be calculated as the sum of all values multiplied by the reciprocal of the number of values.\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{1}{n} \\times \\sum x_1, x_2, x_3, \\cdots , x_n \n",
    "$$\n",
    "\n",
    "In statistics, the mean, or more technically the arithmetic mean or sample mean, can be estimated from a sample of examples drawn from the domain. It is confusing because mean, average, and expected value are used interchangeably. In the abstract, the mean is denoted by the lower case Greek letter mu $\\mu$ and is calculated from the sample of observations, rather than all possible values.\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{n} \\times \\sum x_1, x_2, x_3, \\cdots , x_n \n",
    "$$\n",
    "\n",
    "Or, written more compactly:\n",
    "\n",
    "$$\n",
    "\\mu = P(x) \\times \\sum x\n",
    "$$\n",
    "\n",
    "Where $x$ is the vector of observations and $P(x)$ is the calculated probability for each value. When calculated for a specific variable, such as $x$, the mean is denoted as a lower case variable name with a line above, called x-bar e.g. $\\bar{x}$.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\times \\sum_{i=1}^{n} x_i \n",
    "$$\n",
    "\n",
    "The arithmetic mean can be calculated for a vector or matrix in NumPy by using the `mean()` function. The example below defines a 6-element vector and calculates the mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the defined vector and the mean of the values in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# vector mean\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "# define vector\n",
    "v = array([1,2,3,4,5,6])\n",
    "print(v)\n",
    "# calculate mean\n",
    "result = mean(v)\n",
    "print(f'\\r\\n{result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean function can calculate the row or column means of a matrix by specifying the\n",
    "axis argument and the value 0 or 1 respectively. The example below defines a 2 × 6 matrix and\n",
    "calculates both column and row means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the defined matrix, then the calculated column and row\n",
    "mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "\n",
      "[1. 2. 3. 4. 5. 6.]\n",
      "\n",
      "[3.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "# matrix means\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "# define matrix\n",
    "M = array([\n",
    "[1,2,3,4,5,6],\n",
    "[1,2,3,4,5,6]])\n",
    "print(M)\n",
    "# column means\n",
    "col_mean = mean(M, axis=0)\n",
    "print(f'\\r\\n{col_mean}')\n",
    "# row means\n",
    "row_mean = mean(M, axis=1)\n",
    "print(f'\\r\\n{row_mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability, the variance of some random variable $X$ is a measure of how much values in the distribution vary on average with respect to the mean. The variance is denoted as the function $Var()$ on the variable.\n",
    "\n",
    "$$\n",
    "Var[X]\n",
    "$$\n",
    "\n",
    "Variance is calculated as the average squared difference of each value in the distribution from the expected value. Or the expected squared difference from the expected value.\n",
    "\n",
    "$$\n",
    "Var[X] = E[(X - E[X])^2]\n",
    "$$\n",
    "\n",
    "Assuming the expected value of the variable has been calculated ($E[X]$), the variance of the random variable can be calculated as the sum of the squared difference of each example from the expected value multiplied by the probability of that value.\n",
    "\n",
    "$$\n",
    "Var[X] = \\sum p(x_1) \\times (x_1 - E[X])^2, p(x_2) \\times (x_2 - E[X])^2, \\cdots , p(x_n) \\times (x_n - E[X])^2 \n",
    "$$\n",
    "\n",
    "If the probability of each example in the distribution is equal, variance calculation can drop the individual probabilities and multiply the sum of squared differences by the reciprocal of the number of examples in the distribution.\n",
    "\n",
    "$$\n",
    "Var[X] = \\frac{1}{n} \\times \\sum (x_1 - E[X])^2, (x_2 - E[X])^2, \\cdots , (x_n - E[X])^2\n",
    "$$\n",
    "\n",
    "In statistics, the variance can be estimated from a sample of examples drawn from the domain. In the abstract, the sample variance is denoted by the lower case sigma with a 2 superscript indicating the units are squared (e.g. $\\sigma^2$), not that you must square the final value. The sum of the squared differences is multiplied by the reciprocal of the number of examples minus 1 to correct for a bias (bias is related to a deeper discussion on degrees of freedom and I refer you to references at the end of the lesson).\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n-1} \\times \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "In NumPy, the variance can be calculated for a vector or a matrix using the `var()` function. By default, the `var()` function calculates the population variance. To calculate the sample variance, you must set the `ddof` argument to the value 1. The example below defines a 6-element vector and calculates the sample variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the defined vector and then the calculated sample variance\n",
    "of the values in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# vector variance\n",
    "from numpy import array\n",
    "from numpy import var\n",
    "# define vector\n",
    "v = array([1,2,3,4,5,6])\n",
    "print(v)\n",
    "# calculate variance\n",
    "result = var(v, ddof=1)\n",
    "print(f'\\r\\n{result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The var function can calculate the row or column variances of a matrix by specifying the\n",
    "axis argument and the value 0 or 1 respectively, the same as the mean function above. The\n",
    "example below defines a 2 × 6 matrix and calculates both column and row sample variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the defined matrix and then the column and row sample\n",
    "variance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[3.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "# matrix variances\n",
    "from numpy import array\n",
    "from numpy import var\n",
    "# define matrix\n",
    "M = array([\n",
    "[1,2,3,4,5,6],\n",
    "[1,2,3,4,5,6]])\n",
    "print(M)\n",
    "# column variances\n",
    "col_var = var(M, ddof=1, axis=0)\n",
    "print(f'\\r\\n{col_var}')\n",
    "# row variances\n",
    "row_var = var(M, ddof=1, axis=1)\n",
    "print(f'\\r\\n{row_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is calculated as the square root of the variance and is denoted as lowercase $s$.\n",
    "\n",
    "$$\n",
    "s = \\sqrt{\\sigma^2}\n",
    "$$\n",
    "\n",
    "To keep with this notation, sometimes the variance is indicated as $s^2$, with 2 as a superscript, again showing that the units are squared. NumPy also provides a function for calculating the standard deviation directly via the `std()` function. As with the `var()` function, the `ddof` argument must be set to 1 to calculate the unbiased sample standard deviation and column and row standard deviations can be calculated by setting the axis argument to 0 and 1 respectively. The example below demonstrates how to calculate the sample standard deviation for the rows and columns of a matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the defined matrix and then the column and row sample\n",
    "standard deviation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[1.87082869 1.87082869]\n"
     ]
    }
   ],
   "source": [
    "# matrix standard deviation\n",
    "from numpy import array\n",
    "from numpy import std\n",
    "# define matrix\n",
    "M = array([\n",
    "[1,2,3,4,5,6],\n",
    "[1,2,3,4,5,6]])\n",
    "print(M)\n",
    "# column standard deviations\n",
    "col_std = std(M, ddof=1, axis=0)\n",
    "print(f'\\r\\n{col_std}')\n",
    "# row standard deviations\n",
    "row_std = std(M, ddof=1, axis=1)\n",
    "print(f'\\r\\n{row_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Covariance and Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability, covariance is the measure of the joint probability for two random variables. It describes how the two variables change together. It is denoted as the function $cov(X, Y)$, where $X$ and $Y$ are the two random variables being considered.\n",
    "\n",
    "$$\n",
    "cov(X, Y)\n",
    "$$\n",
    "\n",
    "Covariance is calculated as expected value or average of the product of the differences of each random variable from their expected values, where $E[X]$ is the expected value for $X$ and $E[Y]$ is the expected value of $y$.\n",
    "\n",
    "$$\n",
    "cov(X, Y) = E[(X - E[X]) \\times (Y - E[Y])]\n",
    "$$\n",
    "\n",
    "Assuming the expected values for $X$ and $Y$ have been calculated, the covariance can be calculated as the sum of the difference of $x$ values from their expected value multiplied by the difference of the $y$ values from their expected values multiplied by the reciprocal of the number of examples in the population.\n",
    "\n",
    "$$\n",
    "cov(X, Y) = \\frac{1}{n} \\times \\sum (x - E[X]) \\times (y - E[Y])\n",
    "$$\n",
    "\n",
    "In statistics, the sample covariance can be calculated in the same way, although with a bias correction, the same as with the variance.\n",
    "\n",
    "$$\n",
    "cov(X, Y) = \\frac{1}{n-1} \\times \\sum (x - E[X]) \\times (y - E[Y])\n",
    "$$\n",
    "\n",
    "The sign of the covariance can be interpreted as whether the two variables increase together (positive) or decrease together (negative). The magnitude of the covariance is not easily interpreted. A covariance value of zero indicates that both variables are completely independent. NumPy does not have a function to calculate the covariance between two variables directly. Instead, it has a function for calculating a covariance matrix called `cov()` that we can use to retrieve the covariance. By default, the `cov()` function will calculate the unbiased or sample covariance between the provided random variables.\n",
    "\n",
    "The example below defines two vectors of equal length with one increasing and one decreasing. We would expect the covariance between these variables to be negative. We access just the covariance of the two variables from the [0, 1] element in the square covariance matrix returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "[9 8 7 6 5 4 3 2 1]\n",
      "\n",
      "-7.5\n"
     ]
    }
   ],
   "source": [
    "# vector covariance\n",
    "from numpy import array\n",
    "from numpy import cov\n",
    "# define first vector\n",
    "x = array([1,2,3,4,5,6,7,8,9])\n",
    "print(x)\n",
    "# define second covariance\n",
    "y = array([9,8,7,6,5,4,3,2,1])\n",
    "print(f'\\r\\n{y}')\n",
    "# calculate covariance\n",
    "Sigma = cov(x,y)[0,1]\n",
    "print(f'\\r\\n{Sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance can be normalized to a score between -1 and 1 to make the magnitude interpretable by dividing it by the standard deviation of $X$ and $Y$. The result is called the correlation of the variables, also called the Pearson correlation coefficient, named for the developer of the method.\n",
    "\n",
    "$$\n",
    "r = \\frac{cov(X, Y)}{s_X \\times s_Y}\n",
    "$$\n",
    "\n",
    "Where $r$ is the correlation coefficient of $X$ and $Y$, $cov(X, Y)$ is the sample covariance of $X$ and $Y$ and $s_X$ and $s_Y$ are the standard deviations of $X$ and $Y$ respectively. NumPy provides the `corrcoef()` function for calculating the correlation between two variables directly. Like `cov()`, it returns a matrix, in this case a correlation matrix. As with the results from `cov()` we can access just the correlation of interest from the [0,1] value from the returned squared matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "[9 8 7 6 5 4 3 2 1]\n",
      "\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "# vector correlation\n",
    "from numpy import array\n",
    "from numpy import corrcoef\n",
    "# define first vector\n",
    "x = array([1,2,3,4,5,6,7,8,9])\n",
    "print(x)\n",
    "# define second vector\n",
    "y = array([9,8,7,6,5,4,3,2,1])\n",
    "print(f'\\r\\n{y}')\n",
    "# calculate correlation\n",
    "corr = corrcoef(x,y)[0,1]\n",
    "print(f'\\r\\n{corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix is a square and symmetric matrix that describes the covariance between two or more random variables. The diagonal of the covariance matrix are the variances of each of the random variables, as such it is often called the variance-covariance matrix. A covariance matrix is a generalization of the covariance of two variables and captures the way in which all variables in the dataset may change together. The covariance matrix is denoted as the uppercase Greek letter Sigma, e.g. $\\Sigma$. The covariance for each pair of random variables is calculated as above.\n",
    "\n",
    "$$\n",
    "\\Sigma = E[(X - E[X]) \\times (Y - E[Y])]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\Sigma_{i,j} = cov(X_i, X_j)\n",
    "$$\n",
    "\n",
    "And $X$ is a matrix where each column represents a random variable. The covariance matrix provides a useful tool for separating the structured relationships in a matrix of random variables. This can be used to decorrelate variables or applied as a transform to other variables. It is a key element used in the Principal Component Analysis data reduction method, or PCA for short.\n",
    "\n",
    "The covariance matrix can be calculated in NumPy using the `cov()` function. By default, this function will calculate the sample covariance matrix. The `cov()` function can be called with a single 2D array where each sub-array contains a feature (e.g. column). If this function is called with your data defined in a normal matrix format (rows then columns), then a transpose of the matrix will need to be provided to the function in order to correctly calculate the covariance of the columns. Below is an example that defines a dataset with 5 observations across 3 features and calculates the covariance matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  8]\n",
      " [ 3  5 11]\n",
      " [ 2  4  9]\n",
      " [ 3  6 10]\n",
      " [ 1  5 10]]\n",
      "\n",
      "[[1.   0.25 0.75]\n",
      " [0.25 0.5  0.25]\n",
      " [0.75 0.25 1.3 ]]\n"
     ]
    }
   ],
   "source": [
    "# covariance matrix\n",
    "from numpy import array\n",
    "from numpy import cov\n",
    "# define matrix of observations\n",
    "X = array([\n",
    "[1, 5, 8],\n",
    "[3, 5, 11],\n",
    "[2, 4, 9],\n",
    "[3, 6, 10],\n",
    "[1, 5, 10]])\n",
    "print(X)\n",
    "# calculate covariance matrix\n",
    "Sigma = cov(X.T)\n",
    "print(f'\\r\\n{Sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important machine learning method for dimensionality reduction is called Principal Component Analysis. It is a method that uses simple matrix operations from linear algebra and statistics to calculate a projection of the original data into the same number or fewer dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
